from backend.app.chains import build_conversational_retrieval_chain

import streamlit as st
from streamlit import session_state as sst
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

if "messages" not in sst:
    sst.messages = []
if "custom_retrieval_prompt_template" not in sst:
    sst.custom_retrieval_prompt_template = None
# if "bot_img" not in sst:
#     sst.bot_img = st.image(
#         "https://github.com/wjlee-ling/streamlit/assets/61496071/2c5836a3-666b-47bd-9165-36ab10de76bb"
#     )


@st.cache_resource
def get_conversational_retrieval_chain(retrieval_prompt_template):
    print("â˜‘ï¸ Building a new conversational retrieval chain...")
    conversational_retrieval_chain = build_conversational_retrieval_chain(
        retrieval_prompt_template
    )
    return conversational_retrieval_chain


def reset():
    sst.messages = []
    if sst.custom_retrieval_prompt_template != sst.new_custom_retrieval_prompt_template:
        if (
            "{context}" not in sst.new_custom_retrieval_prompt_template
            and "{question}" not in sst.new_custom_retrieval_prompt_template
        ):
            st.error("{context} ì™€ {question}ì´ ë“¤ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸ í•„ìš”í•©ë‹ˆë‹¤", icon="ğŸ’¥")

        sst.custom_retrieval_prompt_template = ChatPromptTemplate.from_template(
            sst.new_custom_retrieval_prompt_template
        )


st.title("SAL")
with st.expander("ì •ë³´ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ í…œí”Œë ›"):
    new_custom_retrieval_prompt_template = st.text_area(
        ":speech_balloon: ì •ë³´ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸:",
        placeholder="""[ì§ˆë¬¸]ì— [ë¬¸ë§¥]ì„ ê·¼ê±°ë¡œë§Œ ë‹µë³€í•˜ë¼:
[ë¬¸ë§¥] {context}

[ì§ˆë¬¸] {question}
""",
        on_change=reset,
        key="new_custom_retrieval_prompt_template",
    )


for message in sst.messages:
    role = "human" if isinstance(message, HumanMessage) else "ai"

    with st.chat_message(role):
        st.markdown(message.content)

if prompt := st.chat_input("ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Sales Botì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    sst.conversational_retrieval_chain = get_conversational_retrieval_chain(
        sst.custom_retrieval_prompt_template
    )

    # Display user message in chat message container
    with st.chat_message("human"):
        st.markdown(prompt)
    # Add user message to chat history
    sst.messages.append(
        HumanMessage(content=prompt)
    )  # sst.messages.append({"role": "user", "content": prompt})

    # Get assistant response
    print(sst.messages)
    response = sst.conversational_retrieval_chain.invoke(
        {
            "question": prompt,
            "chat_history": sst.messages,
        }
    )
    answer = response["answer"].content
    docs = response["docs"]
    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        st.markdown(answer)
        sst.messages.append(
            AIMessage(content=answer)
        )  # sst.messages.append({"role": "assistant", "content": answer})

        with st.expander("ì •ë³´ ê²€ìƒ‰ ê²°ê³¼"):
            for doc in docs:
                st.info(doc)
